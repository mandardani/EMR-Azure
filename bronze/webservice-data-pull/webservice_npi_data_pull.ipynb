{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e990b7c8-7c90-4e50-b305-3eb54d966c98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import date\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "current_date = date.today() # Gets today's date, suitable for Spark's DateType\n",
    "\n",
    "# Initialize Spark session (often pre-initialized in Databricks)\n",
    "spark = SparkSession.builder.appName(\"NPI Data\").getOrCreate()\n",
    "\n",
    "# Base URL for the NPI Registry API\n",
    "base_url = \"https://npiregistry.cms.hhs.gov/api/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d62260ab-8c09-40e4-b257-74cd1e746002",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defining the parameters for the initial API request\n",
    "params = {\n",
    "    \"version\": \"2.1\",       # Specifies the API version\n",
    "    \"state\": \"CA\",          # Example: Search for providers in California\n",
    "    \"city\": \"Los Angeles\",  # Example: Specifically in Los Angeles\n",
    "    \"limit\": 20,            # Limits the initial results to 20 for demonstration\n",
    "}\n",
    "\n",
    "# Make the initial API request\n",
    "response = requests.get(base_url, params=params)\n",
    "\n",
    "# Check if the request was successful (HTTP status code 200)\n",
    "if response.status_code == 200:\n",
    "    npi_data = response.json() # Parse the JSON response\n",
    "    # Extract only the NPI 'number' from each result in the 'results' list\n",
    "    npi_list = [result[\"number\"] for result in npi_data.get(\"results\", [])]\n",
    "    # ... (rest of the code for detailed fetching)\n",
    "else:\n",
    "    print(f\"Failed to fetch data: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27fc4f95-ac5f-4238-9dae-ae0c3aa1d363",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize a list to store detailed NPI information (dictionaries)\n",
    "detailed_results = []\n",
    "\n",
    "# Loop through each NPI from the initial list\n",
    "for npi in npi_list:\n",
    "    detail_params = {\"version\": \"2.1\", \"number\": npi} # Parameters for specific NPI\n",
    "    detail_response = requests.get(base_url, params=detail_params)\n",
    "\n",
    "    if detail_response.status_code == 200:\n",
    "        detail_data = detail_response.json()\n",
    "        if \"results\" in detail_data and detail_data[\"results\"]:\n",
    "            for result in detail_data[\"results\"]: # Iterate through potential multiple results for an NPI (though usually one)\n",
    "                npi_number = result.get(\"number\")\n",
    "                basic_info = result.get(\"basic\", {}) # Get the 'basic' information block\n",
    "                \n",
    "                # Differentiates between individual (NPI-1) and organizational (NPI-2) providers\n",
    "                if result[\"enumeration_type\"] == \"NPI-1\":\n",
    "                    fname = basic_info.get(\"first_name\", \"\")\n",
    "                    lname = basic_info.get(\"last_name\", \"\")\n",
    "                else: # NPI-2 (Organizational)\n",
    "                    fname = basic_info.get(\"authorized_official_first_name\", \"\")\n",
    "                    lname = basic_info.get(\"authorized_official_last_name\", \"\")\n",
    "                \n",
    "                position = (\n",
    "                    basic_info.get(\"authorized_official_title_or_position\", \"\")\n",
    "                    if \"authorized_official_title_or_position\" in basic_info\n",
    "                    else \"\"\n",
    "                )\n",
    "                organisation = basic_info.get(\"organization_name\", \"\")\n",
    "                last_updated = basic_info.get(\"last_updated\", \"\")\n",
    "                \n",
    "                # Appends a dictionary containing extracted fields to 'detailed_results'\n",
    "                detailed_results.append(\n",
    "                    {\n",
    "                        \"npi_id\": npi_number,\n",
    "                        \"first_name\": fname,\n",
    "                        \"last_name\": lname,\n",
    "                        \"position\": position,\n",
    "                        \"organisation_name\": organisation,\n",
    "                        \"last_updated\": last_updated,\n",
    "                        \"refreshed_at\": current_date, # Adds the current date\n",
    "                    }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71803f79-4d56-4d97-ad65-46a4ca3ce8de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a Spark DataFrame if detailed results were found\n",
    "if detailed_results:\n",
    "    print(detailed_results) # Prints the collected data (useful for debugging)\n",
    "    df = spark.createDataFrame(detailed_results) # Creates the DataFrame\n",
    "    display(df) # Displays the DataFrame in Databricks (for interactive viewing)\n",
    "    \n",
    "    # Save the DataFrame to ADLS Gen2 in Parquet format\n",
    "    df.write.format(\"parquet\").mode(\"overwrite\").save(\"/mnt/bronze/npi_extract/\")\n",
    "    \n",
    "    # Save the DataFrame as a Delta Lake table\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"npi_extract\")\n",
    "else:\n",
    "    print(\"No detailed results found.\") # Message if no data was collected"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "webservice_npi_data_pull",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
